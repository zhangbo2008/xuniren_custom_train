{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/zhangbo2008/xuni8\n!git clone  https://huggingface.co/camenduru/Wav2Lip","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-01T06:15:17.756240Z","iopub.execute_input":"2023-12-01T06:15:17.757034Z","iopub.status.idle":"2023-12-01T06:15:42.668168Z","shell.execute_reply.started":"2023-12-01T06:15:17.756997Z","shell.execute_reply":"2023-12-01T06:15:42.666934Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Cloning into 'xuni8'...\nremote: Enumerating objects: 2380, done.\u001b[K\nremote: Counting objects: 100% (891/891), done.\u001b[K\nremote: Compressing objects: 100% (886/886), done.\u001b[K\nremote: Total 2380 (delta 5), reused 887 (delta 4), pack-reused 1489\u001b[K\nReceiving objects: 100% (2380/2380), 183.10 MiB | 33.80 MiB/s, done.\nResolving deltas: 100% (68/68), done.\nUpdating files: 100% (2859/2859), done.\nCloning into 'Wav2Lip'...\nremote: Enumerating objects: 72, done.\u001b[K\nremote: Counting objects: 100% (3/3), done.\u001b[K\nremote: Compressing objects: 100% (3/3), done.\u001b[K\nremote: Total 72 (delta 0), reused 0 (delta 0), pack-reused 69\u001b[K\nUnpacking objects: 100% (72/72), 442.42 KiB | 6.51 MiB/s, done.\nFiltering content: 100% (6/6), 936.88 MiB | 70.47 MiB/s, done.\n","output_type":"stream"}]},{"cell_type":"code","source":"%cd /kaggle/working/xuni8","metadata":{"execution":{"iopub.status.busy":"2023-12-01T06:15:42.670252Z","iopub.execute_input":"2023-12-01T06:15:42.670600Z","iopub.status.idle":"2023-12-01T06:15:42.678737Z","shell.execute_reply.started":"2023-12-01T06:15:42.670570Z","shell.execute_reply":"2023-12-01T06:15:42.677701Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/working/xuni8\n","output_type":"stream"}]},{"cell_type":"code","source":"# 先需要训练一个syncnet给4.py用. 目标训练一个音频视频是否同步的分类器. 输出是不是同步的概率.\n# import trl\n\nfrom os.path import dirname, join, basename, isfile\nfrom tqdm import tqdm\n\nfrom models import SyncNet_color as SyncNet\nimport audio\nprint(1)\nimport torch\nfrom torch import nn\nfrom torch import optim\nimport torch.backends.cudnn as cudnn\nfrom torch.utils import data as data_utils\nimport numpy as np\nprint(2)\nfrom glob import glob\n\nimport os, random, cv2, argparse\nfrom hparams import hparams, get_image_list\n\nparser = argparse.ArgumentParser(description='Code to train the expert lip-sync discriminator')\n\nparser.add_argument(\"--data_root\", help=\"Root folder of the preprocessed LRS2 dataset\", required=False)\n\nparser.add_argument('--checkpoint_dir', help='Save checkpoints to this directory', required=False, type=str)\nparser.add_argument('--checkpoint_path', help='Resumed from this checkpoint', default=None, type=str)\n\nargs = parser.parse_args('') # kaggle需要传入一个空字符串.\n\nppp='/kaggle/working/Wav2Lip/'\nargs.data_root='lrs2_preprocessed/LRS2_partly'\nargs.checkpoint_dir='./tmp2'\nargs.checkpoint_path=ppp+'checkpoints/lipsync_expert.pth'\n\nglobal_step = 10\nglobal_epoch = 10\nuse_cuda = torch.cuda.is_available()\nprint('use_cuda: {}'.format(use_cuda))\n\nsyncnet_T = 5\nsyncnet_mel_step_size = 16\nhparams.syncnet_checkpoint_interval=300\nhparams.num_workers=0\nhparams.syncnet_batch_size=1000\nhparams.syncnet_lr=3e-5\nclass Dataset(object):\n    def __init__(self, split):\n        # self.all_videos = get_image_list(args.data_root, split)\n        self.all_videos =glob('my_data_preprocessed/20171116/*')\n        print(self.all_videos)\n    def get_frame_id(self, frame):\n        return int(basename(frame).split('.')[0])\n\n    def get_window(self, start_frame):\n        start_id = self.get_frame_id(start_frame)\n        vidname = dirname(start_frame)\n\n        window_fnames = []\n        for frame_id in range(start_id, start_id + syncnet_T):\n            frame = join(vidname, '{}.jpg'.format(frame_id))\n            if not isfile(frame):\n                return None\n            window_fnames.append(frame)\n        return window_fnames\n\n    def crop_audio_window(self, spec, start_frame):\n        # num_frames = (T x hop_size * fps) / sample_rate\n        start_frame_num = self.get_frame_id(start_frame)\n        start_idx = int(80. * (start_frame_num / float(hparams.fps)))\n\n        end_idx = start_idx + syncnet_mel_step_size\n\n        return spec[start_idx : end_idx, :]\n\n\n    def __len__(self):\n        return len(self.all_videos)\n\n    def __getitem__(self, idx):\n        while 1:\n            idx = random.randint(0, len(self.all_videos) - 1)\n            vidname = self.all_videos[idx] # 随便抽取一个视频.\n\n            img_names = list(glob(join(vidname, '*.jpg')))\n            if len(img_names) <= 3 * syncnet_T:\n                continue\n            img_name = random.choice(img_names)\n            wrong_img_name = random.choice(img_names)\n            while wrong_img_name == img_name:\n                wrong_img_name = random.choice(img_names)\n            #选一个真或者假照片.\n            if random.choice([True, False]):\n                y = torch.ones(1).float()\n                chosen = img_name\n            else:\n                y = torch.zeros(1).float()\n                chosen = wrong_img_name\n\n            window_fnames = self.get_window(chosen)\n            if window_fnames is None:\n                continue\n\n            window = []\n            all_read = True\n            for fname in window_fnames:\n                img = cv2.imread(fname)\n                if img is None:\n                    all_read = False\n                    break\n                try:\n                    img = cv2.resize(img, (hparams.img_size, hparams.img_size))\n                except Exception as e:\n                    all_read = False\n                    break\n\n                window.append(img)\n\n            if not all_read: continue\n\n            if 1:\n#                 print(88888888888888888,vidname)\n                aaa=list(glob(join(vidname, '*.wav')))[0]\n                wavpath = join(vidname, \"audio.wav\")\n#                 print(aaa,333333333)\n                wav = audio.load_wav(aaa, hparams.sample_rate) # 输入音频原始的sr不用管, 这里面设置好我们需要的sr即可.16000.\n#                 print(222222222)\n                orig_mel = audio.melspectrogram(wav).T\n#             except Exception as e:\n#                 continue\n#=======根据片段拿到真实的读音.\n            mel = self.crop_audio_window(orig_mel.copy(), img_name)\n\n            if (mel.shape[0] != syncnet_mel_step_size):\n                continue\n\n            # H x W x 3 * T\n            x = np.concatenate(window, axis=2) / 255.\n            x = x.transpose(2, 0, 1)\n            x = x[:, x.shape[1]//2:] #################????????????????????????????????????????????????????为啥要切一半呢?????????????????我理解是人脸嘴的部分一定在图片的下半部分, 所以去掉上面, 会加速网络收敛.\n\n            x = torch.FloatTensor(x)\n            mel = torch.FloatTensor(mel.T).unsqueeze(0)\n\n            return x, mel, y\n\nlogloss = nn.BCELoss()\ndef cosine_loss(a, v, y):\n    d = nn.functional.cosine_similarity(a, v)\n    loss = logloss(d.unsqueeze(1), y)\n\n    return loss\n\ndef train(device, model, train_data_loader, test_data_loader, optimizer,\n          checkpoint_dir=None, checkpoint_interval=None, nepochs=None):\n\n    global global_step, global_epoch\n    resumed_step = global_step\n    \n    while global_epoch < nepochs:\n        running_loss = 0.\n        prog_bar = tqdm(enumerate(train_data_loader))\n#         print(global_epoch,'global_epoch')\n        for step, (x, mel, y) in prog_bar:\n#             print(step,'step')\n            model.train()\n            optimizer.zero_grad()\n\n            # Transform data to CUDA device\n            x = x.to(device)\n\n            mel = mel.to(device)\n\n            a, v = model(mel, x) # a:audio v:video 都是512向量.\n            y = y.to(device)\n\n            loss = cosine_loss(a, v, y)\n            loss.backward()\n            optimizer.step()\n\n            global_step += 1\n            cur_session_steps = global_step - resumed_step\n            running_loss += loss.item()\n\n            if global_step == 1 or global_step % checkpoint_interval == 0:\n                save_checkpoint(\n                    model, optimizer, global_step, checkpoint_dir, global_epoch)\n\n            if global_step % hparams.syncnet_eval_interval == 0:\n                with torch.no_grad():\n                    eval_model(test_data_loader, global_step, device, model, checkpoint_dir)\n\n            prog_bar.set_description(f'Loss: {running_loss / (step + 1)},epoch:{global_step}')\n\n        global_epoch += 1\n\ndef eval_model(test_data_loader, global_step, device, model, checkpoint_dir):\n    eval_steps = 1400\n    print('Evaluating for {} steps'.format(eval_steps))\n    losses = []\n    while 1:\n        for step, (x, mel, y) in enumerate(test_data_loader):\n\n            model.eval()\n\n            # Transform data to CUDA device\n            x = x.to(device)\n\n            mel = mel.to(device)\n\n            a, v = model(mel, x)\n            y = y.to(device)\n\n            loss = cosine_loss(a, v, y)\n            losses.append(loss.item())\n\n            if step > eval_steps: break\n\n        averaged_loss = sum(losses) / len(losses)\n        print(averaged_loss)\n\n        return\n\ndef save_checkpoint(model, optimizer, step, checkpoint_dir, epoch):\n\n    checkpoint_path = join(\n        checkpoint_dir, \"checkpoint_step{:09d}.pth\".format(global_step))\n    optimizer_state = optimizer.state_dict() if hparams.save_optimizer_state else None\n    torch.save({\n        \"state_dict\": model.state_dict(),\n        \"optimizer\": optimizer_state,\n        \"global_step\": step,\n        \"global_epoch\": epoch,\n    }, checkpoint_path)\n    print(\"Saved checkpoint:\", checkpoint_path)\n\ndef _load(checkpoint_path):\n    if use_cuda:\n        checkpoint = torch.load(checkpoint_path)\n    else:\n        checkpoint = torch.load(checkpoint_path,\n                                map_location=lambda storage, loc: storage)\n    return checkpoint\n\ndef load_checkpoint(path, model, optimizer, reset_optimizer=False):\n    global global_step\n    global global_epoch\n\n    print(\"Load checkpoint from: {}\".format(path))\n    checkpoint = _load(path)\n    model.load_state_dict(checkpoint[\"state_dict\"])\n    if not reset_optimizer:\n        optimizer_state = checkpoint[\"optimizer\"]\n        if optimizer_state is not None:\n            print(\"Load optimizer state from {}\".format(path))\n            optimizer.load_state_dict(checkpoint[\"optimizer\"])\n    global_step = checkpoint[\"global_step\"]\n    global_epoch = checkpoint[\"global_epoch\"]\n\n    return model\n\nif __name__ == \"__main__\":\n    checkpoint_dir = args.checkpoint_dir\n    checkpoint_path = args.checkpoint_path\n\n    if not os.path.exists(checkpoint_dir): os.mkdir(checkpoint_dir)\n\n    # Dataset and Dataloader setup\n    train_dataset = Dataset('train')\n    test_dataset = Dataset('val')\n\n    train_data_loader = data_utils.DataLoader(\n        train_dataset, batch_size=hparams.syncnet_batch_size, shuffle=True,\n        num_workers=hparams.num_workers)\n\n    test_data_loader = data_utils.DataLoader(\n        test_dataset, batch_size=hparams.syncnet_batch_size,\n        num_workers=8)\n\n    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n\n    # Model\n    model = SyncNet().to(device)\n    print('total trainable params {}'.format(sum(p.numel() for p in model.parameters() if p.requires_grad)))\n\n    optimizer = optim.Adam([p for p in model.parameters() if p.requires_grad],\n                           lr=hparams.syncnet_lr)\n\n    if checkpoint_path is not None:\n        load_checkpoint(checkpoint_path, model, optimizer, reset_optimizer=False)\n\n    train(device, model, train_data_loader, test_data_loader, optimizer,\n          checkpoint_dir=checkpoint_dir,\n          checkpoint_interval=hparams.syncnet_checkpoint_interval,\n          nepochs=hparams.nepochs)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-01T06:44:34.051734Z","iopub.execute_input":"2023-12-01T06:44:34.052280Z","iopub.status.idle":"2023-12-01T06:46:57.354831Z","shell.execute_reply.started":"2023-12-01T06:44:34.052246Z","shell.execute_reply":"2023-12-01T06:46:57.353167Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"1\n2\nuse_cuda: True\n['my_data_preprocessed/20171116/section_2_028', 'my_data_preprocessed/20171116/section_3_000', 'my_data_preprocessed/20171116/section_1_081', 'my_data_preprocessed/20171116/section_2_033', 'my_data_preprocessed/20171116/section_1_049', 'my_data_preprocessed/20171116/section_2_024', 'my_data_preprocessed/20171116/section_2_020', 'my_data_preprocessed/20171116/section_1_024', 'my_data_preprocessed/20171116/section_1_068', 'my_data_preprocessed/20171116/section_2_016']\n['my_data_preprocessed/20171116/section_2_028', 'my_data_preprocessed/20171116/section_3_000', 'my_data_preprocessed/20171116/section_1_081', 'my_data_preprocessed/20171116/section_2_033', 'my_data_preprocessed/20171116/section_1_049', 'my_data_preprocessed/20171116/section_2_024', 'my_data_preprocessed/20171116/section_2_020', 'my_data_preprocessed/20171116/section_1_024', 'my_data_preprocessed/20171116/section_1_068', 'my_data_preprocessed/20171116/section_2_016']\ntotal trainable params 16435072\nLoad checkpoint from: /kaggle/working/Wav2Lip/checkpoints/lipsync_expert.pth\nLoad optimizer state from /kaggle/working/Wav2Lip/checkpoints/lipsync_expert.pth\n","output_type":"stream"},{"name":"stderr","text":"Loss: 0.767553985118866,epoch:1751231: : 1it [00:00,  2.95it/s]\nLoss: 0.877458393573761,epoch:1751232: : 1it [00:00,  3.18it/s]\nLoss: 0.4243386685848236,epoch:1751233: : 1it [00:00,  2.62it/s]\nLoss: 0.5802802443504333,epoch:1751234: : 1it [00:00,  2.75it/s]\nLoss: 0.7357434630393982,epoch:1751235: : 1it [00:00,  2.46it/s]\nLoss: 0.42107173800468445,epoch:1751236: : 1it [00:00,  2.40it/s]\nLoss: 0.3131580948829651,epoch:1751237: : 1it [00:00,  2.59it/s]\nLoss: 0.3601432740688324,epoch:1751238: : 1it [00:00,  2.84it/s]\nLoss: 0.5840126872062683,epoch:1751239: : 1it [00:00,  3.62it/s]\nLoss: 0.42108169198036194,epoch:1751240: : 1it [00:00,  2.39it/s]\nLoss: 0.5986115336418152,epoch:1751241: : 1it [00:00,  2.24it/s]\nLoss: 0.8161717653274536,epoch:1751242: : 1it [00:00,  2.65it/s]\nLoss: 0.2917346954345703,epoch:1751243: : 1it [00:00,  2.79it/s]\nLoss: 0.43913522362709045,epoch:1751244: : 1it [00:00,  1.91it/s]\nLoss: 0.37753230333328247,epoch:1751245: : 1it [00:00,  2.47it/s]\nLoss: 0.5822505354881287,epoch:1751246: : 1it [00:00,  2.67it/s]\nLoss: 0.5597637295722961,epoch:1751247: : 1it [00:00,  2.96it/s]\nLoss: 0.518825352191925,epoch:1751248: : 1it [00:00,  2.38it/s]\nLoss: 0.4802471697330475,epoch:1751249: : 1it [00:00,  2.71it/s]\nLoss: 0.578432023525238,epoch:1751250: : 1it [00:00,  2.44it/s]\nLoss: 0.3280523717403412,epoch:1751251: : 1it [00:00,  3.07it/s]\nLoss: 0.3517063558101654,epoch:1751252: : 1it [00:00,  2.95it/s]\nLoss: 0.9415518641471863,epoch:1751253: : 1it [00:00,  2.86it/s]\nLoss: 1.1848262548446655,epoch:1751254: : 1it [00:00,  2.49it/s]\nLoss: 0.6355236172676086,epoch:1751255: : 1it [00:00,  2.72it/s]\nLoss: 0.4091055989265442,epoch:1751256: : 1it [00:00,  2.65it/s]\nLoss: 0.5917659997940063,epoch:1751257: : 1it [00:00,  2.55it/s]\nLoss: 0.9229076504707336,epoch:1751258: : 1it [00:00,  2.16it/s]\nLoss: 0.38543328642845154,epoch:1751259: : 1it [00:00,  2.03it/s]\nLoss: 0.5218278765678406,epoch:1751260: : 1it [00:00,  1.47it/s]\nLoss: 0.2946411669254303,epoch:1751261: : 1it [00:00,  2.01it/s]\nLoss: 1.0186623334884644,epoch:1751262: : 1it [00:00,  1.96it/s]\nLoss: 0.5551508665084839,epoch:1751263: : 1it [00:00,  2.19it/s]\nLoss: 0.5054157376289368,epoch:1751264: : 1it [00:00,  2.40it/s]\nLoss: 0.6600913405418396,epoch:1751265: : 1it [00:00,  2.20it/s]\nLoss: 0.35963544249534607,epoch:1751266: : 1it [00:00,  2.74it/s]\nLoss: 0.7279874682426453,epoch:1751267: : 1it [00:00,  2.42it/s]\nLoss: 0.4677405059337616,epoch:1751268: : 1it [00:00,  1.88it/s]\nLoss: 0.7813602089881897,epoch:1751269: : 1it [00:00,  2.48it/s]\nLoss: 1.0143136978149414,epoch:1751270: : 1it [00:00,  2.58it/s]\nLoss: 0.42916783690452576,epoch:1751271: : 1it [00:00,  1.79it/s]\nLoss: 0.5210394263267517,epoch:1751272: : 1it [00:00,  1.76it/s]\nLoss: 0.3428490161895752,epoch:1751273: : 1it [00:00,  2.55it/s]\nLoss: 1.2238456010818481,epoch:1751274: : 1it [00:00,  2.91it/s]\nLoss: 0.1872764676809311,epoch:1751275: : 1it [00:00,  1.95it/s]\nLoss: 0.4838733375072479,epoch:1751276: : 1it [00:00,  2.08it/s]\nLoss: 0.5346631407737732,epoch:1751277: : 1it [00:00,  2.11it/s]\nLoss: 0.7445300221443176,epoch:1751278: : 1it [00:00,  2.14it/s]\nLoss: 0.3906254470348358,epoch:1751279: : 1it [00:00,  2.58it/s]\nLoss: 1.0816713571548462,epoch:1751280: : 1it [00:00,  2.33it/s]\nLoss: 0.37325742840766907,epoch:1751281: : 1it [00:00,  2.96it/s]\nLoss: 0.8542448282241821,epoch:1751282: : 1it [00:00,  1.89it/s]\nLoss: 0.7277848720550537,epoch:1751283: : 1it [00:00,  2.82it/s]\nLoss: 0.6530417799949646,epoch:1751284: : 1it [00:00,  2.67it/s]\nLoss: 0.5224749445915222,epoch:1751285: : 1it [00:00,  2.40it/s]\nLoss: 0.39350414276123047,epoch:1751286: : 1it [00:00,  2.66it/s]\nLoss: 0.5941682457923889,epoch:1751287: : 1it [00:00,  3.17it/s]\nLoss: 0.2885896563529968,epoch:1751288: : 1it [00:00,  2.17it/s]\nLoss: 0.40636640787124634,epoch:1751289: : 1it [00:00,  2.52it/s]\nLoss: 0.1945401430130005,epoch:1751290: : 1it [00:00,  2.39it/s]\nLoss: 0.3246094286441803,epoch:1751291: : 1it [00:00,  2.81it/s]\nLoss: 0.4908126890659332,epoch:1751292: : 1it [00:00,  2.74it/s]\nLoss: 0.4313647747039795,epoch:1751293: : 1it [00:00,  2.45it/s]\nLoss: 0.2604670226573944,epoch:1751294: : 1it [00:00,  2.15it/s]\nLoss: 0.2848016917705536,epoch:1751295: : 1it [00:00,  2.41it/s]\nLoss: 0.4312255084514618,epoch:1751296: : 1it [00:00,  2.27it/s]\nLoss: 0.9984468817710876,epoch:1751297: : 1it [00:00,  1.72it/s]\nLoss: 0.23346899449825287,epoch:1751298: : 1it [00:00,  2.18it/s]\nLoss: 0.5125513076782227,epoch:1751299: : 1it [00:00,  1.96it/s]\nLoss: 0.19202081859111786,epoch:1751300: : 1it [00:00,  2.93it/s]\nLoss: 0.372488409280777,epoch:1751301: : 1it [00:00,  2.79it/s]\nLoss: 0.38597509264945984,epoch:1751302: : 1it [00:00,  2.53it/s]\nLoss: 0.5851466655731201,epoch:1751303: : 1it [00:00,  2.80it/s]\nLoss: 0.4337696135044098,epoch:1751304: : 1it [00:00,  2.69it/s]\nLoss: 0.5350675582885742,epoch:1751305: : 1it [00:00,  2.53it/s]\nLoss: 0.5496000647544861,epoch:1751306: : 1it [00:00,  2.97it/s]\nLoss: 0.7031119465827942,epoch:1751307: : 1it [00:00,  2.89it/s]\nLoss: 0.26370397210121155,epoch:1751308: : 1it [00:00,  1.89it/s]\nLoss: 0.5891868472099304,epoch:1751309: : 1it [00:00,  2.72it/s]\nLoss: 0.565761923789978,epoch:1751310: : 1it [00:00,  2.70it/s]\nLoss: 0.3340371549129486,epoch:1751311: : 1it [00:00,  2.26it/s]\nLoss: 0.3890095055103302,epoch:1751312: : 1it [00:00,  3.32it/s]\nLoss: 0.4207022786140442,epoch:1751313: : 1it [00:00,  2.53it/s]\nLoss: 0.356150358915329,epoch:1751314: : 1it [00:00,  2.55it/s]\nLoss: 0.7821236848831177,epoch:1751315: : 1it [00:00,  2.74it/s]\nLoss: 0.35149869322776794,epoch:1751316: : 1it [00:00,  2.49it/s]\nLoss: 0.29381218552589417,epoch:1751317: : 1it [00:00,  2.62it/s]\nLoss: 0.540224552154541,epoch:1751318: : 1it [00:00,  2.17it/s]\nLoss: 0.6090382933616638,epoch:1751319: : 1it [00:00,  2.72it/s]\nLoss: 0.18825839459896088,epoch:1751320: : 1it [00:00,  2.72it/s]\nLoss: 0.36711928248405457,epoch:1751321: : 1it [00:00,  2.36it/s]\nLoss: 0.5551009178161621,epoch:1751322: : 1it [00:00,  1.91it/s]\nLoss: 0.26124507188796997,epoch:1751323: : 1it [00:00,  2.85it/s]\nLoss: 0.7686613202095032,epoch:1751324: : 1it [00:00,  2.55it/s]\nLoss: 0.49038225412368774,epoch:1751325: : 1it [00:00,  4.38it/s]\nLoss: 0.18457730114459991,epoch:1751326: : 1it [00:00,  2.28it/s]\nLoss: 0.6843207478523254,epoch:1751327: : 1it [00:00,  2.58it/s]\nLoss: 0.6176708340644836,epoch:1751328: : 1it [00:00,  2.18it/s]\nLoss: 0.5155016779899597,epoch:1751329: : 1it [00:00,  2.82it/s]\nLoss: 0.2691616117954254,epoch:1751330: : 1it [00:00,  1.73it/s]\nLoss: 0.401521772146225,epoch:1751331: : 1it [00:00,  2.79it/s]\nLoss: 0.5499851107597351,epoch:1751332: : 1it [00:00,  2.53it/s]\nLoss: 0.43375158309936523,epoch:1751333: : 1it [00:00,  1.76it/s]\nLoss: 0.3295133113861084,epoch:1751334: : 1it [00:00,  1.59it/s]\nLoss: 0.33354613184928894,epoch:1751335: : 1it [00:00,  1.42it/s]\nLoss: 0.6596004962921143,epoch:1751336: : 1it [00:00,  1.53it/s]\nLoss: 0.21079790592193604,epoch:1751337: : 1it [00:00,  2.68it/s]\nLoss: 0.46639329195022583,epoch:1751338: : 1it [00:00,  2.30it/s]\nLoss: 0.5304719805717468,epoch:1751339: : 1it [00:00,  2.50it/s]\nLoss: 0.46862244606018066,epoch:1751340: : 1it [00:00,  2.99it/s]\nLoss: 0.2064753770828247,epoch:1751341: : 1it [00:00,  2.24it/s]\nLoss: 0.3977035880088806,epoch:1751342: : 1it [00:00,  2.70it/s]\nLoss: 0.3966692388057709,epoch:1751343: : 1it [00:00,  2.25it/s]\nLoss: 0.18031425774097443,epoch:1751344: : 1it [00:00,  2.68it/s]\nLoss: 0.5559731721878052,epoch:1751345: : 1it [00:00,  2.12it/s]\nLoss: 0.3908125162124634,epoch:1751346: : 1it [00:00,  2.24it/s]\nLoss: 0.16760991513729095,epoch:1751347: : 1it [00:00,  2.59it/s]\nLoss: 0.2673775255680084,epoch:1751348: : 1it [00:00,  2.42it/s]\nLoss: 0.3196008801460266,epoch:1751349: : 1it [00:00,  2.04it/s]\nLoss: 0.39745160937309265,epoch:1751350: : 1it [00:00,  2.62it/s]\nLoss: 0.2387700080871582,epoch:1751351: : 1it [00:00,  3.62it/s]\nLoss: 0.14229939877986908,epoch:1751352: : 1it [00:00,  1.96it/s]\nLoss: 0.45009851455688477,epoch:1751353: : 1it [00:00,  2.41it/s]\nLoss: 0.3700014054775238,epoch:1751354: : 1it [00:00,  3.22it/s]\nLoss: 0.4480142593383789,epoch:1751355: : 1it [00:00,  2.84it/s]\nLoss: 0.2931216061115265,epoch:1751356: : 1it [00:00,  2.88it/s]\nLoss: 0.23412440717220306,epoch:1751357: : 1it [00:00,  2.42it/s]\nLoss: 0.6284315586090088,epoch:1751358: : 1it [00:00,  2.57it/s]\nLoss: 0.6897563338279724,epoch:1751359: : 1it [00:00,  3.10it/s]\nLoss: 0.30388158559799194,epoch:1751360: : 1it [00:00,  2.88it/s]\nLoss: 0.2506439685821533,epoch:1751361: : 1it [00:00,  2.55it/s]\nLoss: 0.5418359041213989,epoch:1751362: : 1it [00:00,  3.31it/s]\nLoss: 0.22315049171447754,epoch:1751363: : 1it [00:00,  2.70it/s]\nLoss: 0.3545868396759033,epoch:1751364: : 1it [00:00,  3.22it/s]\nLoss: 0.48649272322654724,epoch:1751365: : 1it [00:00,  2.48it/s]\nLoss: 0.37020525336265564,epoch:1751366: : 1it [00:00,  2.56it/s]\nLoss: 0.2909396290779114,epoch:1751367: : 1it [00:00,  3.08it/s]\nLoss: 0.24771641194820404,epoch:1751368: : 1it [00:00,  2.79it/s]\nLoss: 0.43152013421058655,epoch:1751369: : 1it [00:00,  2.73it/s]\nLoss: 0.925421416759491,epoch:1751370: : 1it [00:00,  2.71it/s]\nLoss: 0.5248505473136902,epoch:1751371: : 1it [00:00,  3.05it/s]\nLoss: 0.4691341519355774,epoch:1751372: : 1it [00:00,  3.38it/s]\nLoss: 0.6014426350593567,epoch:1751373: : 1it [00:00,  2.62it/s]\nLoss: 0.5761913657188416,epoch:1751374: : 1it [00:00,  2.48it/s]\nLoss: 0.27901265025138855,epoch:1751375: : 1it [00:00,  2.26it/s]\nLoss: 0.7149831056594849,epoch:1751376: : 1it [00:00,  2.47it/s]\nLoss: 0.28740450739860535,epoch:1751377: : 1it [00:00,  2.49it/s]\nLoss: 0.21424689888954163,epoch:1751378: : 1it [00:00,  2.12it/s]\nLoss: 0.264137327671051,epoch:1751379: : 1it [00:00,  2.53it/s]\nLoss: 0.36150452494621277,epoch:1751380: : 1it [00:00,  2.68it/s]\nLoss: 0.46564504504203796,epoch:1751381: : 1it [00:00,  2.87it/s]\nLoss: 0.38615113496780396,epoch:1751382: : 1it [00:00,  2.52it/s]\nLoss: 0.4323886036872864,epoch:1751383: : 1it [00:00,  2.51it/s]\nLoss: 0.4774223268032074,epoch:1751384: : 1it [00:00,  2.42it/s]\nLoss: 0.30716750025749207,epoch:1751385: : 1it [00:00,  2.37it/s]\nLoss: 0.35049259662628174,epoch:1751386: : 1it [00:00,  2.89it/s]\nLoss: 0.4070214331150055,epoch:1751387: : 1it [00:00,  2.31it/s]\nLoss: 0.38417166471481323,epoch:1751388: : 1it [00:00,  2.45it/s]\nLoss: 0.3763149380683899,epoch:1751389: : 1it [00:00,  2.23it/s]\nLoss: 0.6487705111503601,epoch:1751390: : 1it [00:00,  2.68it/s]\nLoss: 0.3127027153968811,epoch:1751391: : 1it [00:00,  2.69it/s]\nLoss: 0.348810613155365,epoch:1751392: : 1it [00:00,  2.79it/s]\nLoss: 0.2351294308900833,epoch:1751393: : 1it [00:00,  2.51it/s]\nLoss: 0.22420434653759003,epoch:1751394: : 1it [00:00,  2.55it/s]\nLoss: 0.32518523931503296,epoch:1751395: : 1it [00:00,  2.54it/s]\nLoss: 0.4484454095363617,epoch:1751396: : 1it [00:00,  2.04it/s]\nLoss: 0.27981123328208923,epoch:1751397: : 1it [00:00,  2.61it/s]\nLoss: 0.2892501950263977,epoch:1751398: : 1it [00:00,  2.12it/s]\nLoss: 0.5357800722122192,epoch:1751399: : 1it [00:00,  2.32it/s]\nLoss: 0.15463073551654816,epoch:1751400: : 1it [00:00,  1.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved checkpoint: ./tmp2/checkpoint_step001751400.pth\n","output_type":"stream"},{"name":"stderr","text":"Loss: 0.34751930832862854,epoch:1751401: : 1it [00:00,  2.27it/s]\nLoss: 0.5574396848678589,epoch:1751402: : 1it [00:00,  1.76it/s]\nLoss: 0.19069352746009827,epoch:1751403: : 1it [00:00,  2.57it/s]\nLoss: 10.310107231140137,epoch:1751404: : 1it [00:00,  1.99it/s]\nLoss: 0.48897430300712585,epoch:1751405: : 1it [00:00,  1.74it/s]\nLoss: 0.3920682966709137,epoch:1751406: : 1it [00:00,  3.63it/s]\nLoss: 0.29813045263290405,epoch:1751407: : 1it [00:00,  2.74it/s]\nLoss: 0.6438532471656799,epoch:1751408: : 1it [00:00,  2.22it/s]\nLoss: 0.4431682527065277,epoch:1751409: : 1it [00:00,  2.54it/s]\nLoss: 0.1764533817768097,epoch:1751410: : 1it [00:00,  1.77it/s]\nLoss: 0.5738363862037659,epoch:1751411: : 1it [00:00,  2.52it/s]\nLoss: 0.14858652651309967,epoch:1751412: : 1it [00:00,  2.19it/s]\nLoss: 0.36434322595596313,epoch:1751413: : 1it [00:00,  2.15it/s]\nLoss: 0.6783915758132935,epoch:1751414: : 1it [00:00,  1.61it/s]\nLoss: 0.628143310546875,epoch:1751415: : 1it [00:00,  2.66it/s]\nLoss: 0.4476298391819,epoch:1751416: : 1it [00:00,  2.47it/s]\nLoss: 0.24921360611915588,epoch:1751417: : 1it [00:00,  2.63it/s]\nLoss: 0.3353736102581024,epoch:1751418: : 1it [00:00,  2.44it/s]\nLoss: 0.4355130195617676,epoch:1751419: : 1it [00:00,  2.72it/s]\nLoss: 0.2994135320186615,epoch:1751420: : 1it [00:00,  2.79it/s]\nLoss: 0.3392140567302704,epoch:1751421: : 1it [00:00,  2.73it/s]\nLoss: 0.6877539753913879,epoch:1751422: : 1it [00:00,  2.50it/s]\nLoss: 0.417105495929718,epoch:1751423: : 1it [00:00,  2.20it/s]\nLoss: 0.3194492757320404,epoch:1751424: : 1it [00:00,  2.00it/s]\nLoss: 0.23859062790870667,epoch:1751425: : 1it [00:00,  2.36it/s]\nLoss: 0.5432450175285339,epoch:1751426: : 1it [00:00,  2.27it/s]\nLoss: 0.5563732981681824,epoch:1751427: : 1it [00:00,  2.44it/s]\nLoss: 0.22455532848834991,epoch:1751428: : 1it [00:00,  2.25it/s]\nLoss: 0.21026895940303802,epoch:1751429: : 1it [00:00,  2.21it/s]\nLoss: 0.5706042647361755,epoch:1751430: : 1it [00:00,  2.52it/s]\nLoss: 0.35714197158813477,epoch:1751431: : 1it [00:00,  1.74it/s]\nLoss: 0.20373792946338654,epoch:1751432: : 1it [00:00,  2.68it/s]\nLoss: 0.3615502119064331,epoch:1751433: : 1it [00:00,  1.85it/s]\nLoss: 0.25848615169525146,epoch:1751434: : 1it [00:00,  2.44it/s]\nLoss: 0.7853795886039734,epoch:1751435: : 1it [00:00,  2.49it/s]\nLoss: 0.5812147259712219,epoch:1751436: : 1it [00:00,  2.51it/s]\nLoss: 0.29459407925605774,epoch:1751437: : 1it [00:00,  2.64it/s]\nLoss: 0.3986775577068329,epoch:1751438: : 1it [00:00,  2.38it/s]\nLoss: 0.40929242968559265,epoch:1751439: : 1it [00:00,  2.50it/s]\nLoss: 0.6226381659507751,epoch:1751440: : 1it [00:00,  2.16it/s]\nLoss: 0.2942568361759186,epoch:1751441: : 1it [00:00,  2.62it/s]\nLoss: 0.4688948690891266,epoch:1751442: : 1it [00:00,  2.92it/s]\nLoss: 0.5155443549156189,epoch:1751443: : 1it [00:00,  2.64it/s]\nLoss: 0.36294659972190857,epoch:1751444: : 1it [00:00,  2.37it/s]\nLoss: 0.34281036257743835,epoch:1751445: : 1it [00:00,  2.41it/s]\nLoss: 0.22307491302490234,epoch:1751446: : 1it [00:00,  3.43it/s]\nLoss: 0.32828694581985474,epoch:1751447: : 1it [00:00,  2.51it/s]\nLoss: 0.5058286786079407,epoch:1751448: : 1it [00:00,  2.67it/s]\nLoss: 0.29927903413772583,epoch:1751449: : 1it [00:00,  2.57it/s]\nLoss: 0.2350219339132309,epoch:1751450: : 1it [00:00,  2.37it/s]\nLoss: 0.2837543189525604,epoch:1751451: : 1it [00:00,  2.22it/s]\nLoss: 0.3275533616542816,epoch:1751452: : 1it [00:00,  2.62it/s]\nLoss: 0.28807926177978516,epoch:1751453: : 1it [00:00,  3.17it/s]\nLoss: 0.35584941506385803,epoch:1751454: : 1it [00:00,  2.64it/s]\nLoss: 0.2640783488750458,epoch:1751455: : 1it [00:00,  2.69it/s]\nLoss: 0.268117219209671,epoch:1751456: : 1it [00:00,  2.82it/s]\nLoss: 0.27621179819107056,epoch:1751457: : 1it [00:00,  2.09it/s]\nLoss: 0.25511038303375244,epoch:1751458: : 1it [00:00,  2.11it/s]\nLoss: 0.2809983193874359,epoch:1751459: : 1it [00:00,  2.22it/s]\nLoss: 0.4112769067287445,epoch:1751460: : 1it [00:00,  2.32it/s]\nLoss: 0.3984864354133606,epoch:1751461: : 1it [00:00,  2.55it/s]\nLoss: 0.335999459028244,epoch:1751462: : 1it [00:00,  2.25it/s]\nLoss: 0.420449823141098,epoch:1751463: : 1it [00:00,  2.65it/s]\nLoss: 0.8242301344871521,epoch:1751464: : 1it [00:00,  3.45it/s]\nLoss: 0.24070079624652863,epoch:1751465: : 1it [00:00,  2.19it/s]\nLoss: 0.16180828213691711,epoch:1751466: : 1it [00:00,  2.61it/s]\nLoss: 0.2556004226207733,epoch:1751467: : 1it [00:00,  3.13it/s]\nLoss: 0.32778695225715637,epoch:1751468: : 1it [00:00,  2.97it/s]\nLoss: 0.19960841536521912,epoch:1751469: : 1it [00:00,  2.91it/s]\nLoss: 0.241397425532341,epoch:1751470: : 1it [00:00,  2.69it/s]\nLoss: 0.19159574806690216,epoch:1751471: : 1it [00:00,  3.59it/s]\nLoss: 0.38528940081596375,epoch:1751472: : 1it [00:00,  2.05it/s]\nLoss: 0.4194936454296112,epoch:1751473: : 1it [00:00,  2.38it/s]\nLoss: 0.5298249125480652,epoch:1751474: : 1it [00:00,  2.48it/s]\nLoss: 0.4899819493293762,epoch:1751475: : 1it [00:00,  2.33it/s]\nLoss: 0.3635179102420807,epoch:1751476: : 1it [00:00,  2.63it/s]\nLoss: 0.2330901175737381,epoch:1751477: : 1it [00:00,  2.43it/s]\nLoss: 0.36226511001586914,epoch:1751478: : 1it [00:00,  2.81it/s]\nLoss: 0.5299645066261292,epoch:1751479: : 1it [00:00,  2.61it/s]\nLoss: 0.2826097905635834,epoch:1751480: : 1it [00:00,  2.92it/s]\nLoss: 0.4582357108592987,epoch:1751481: : 1it [00:00,  2.52it/s]\nLoss: 0.33016061782836914,epoch:1751482: : 1it [00:00,  2.37it/s]\nLoss: 0.23371465504169464,epoch:1751483: : 1it [00:00,  3.55it/s]\nLoss: 0.4245580732822418,epoch:1751484: : 1it [00:00,  1.86it/s]\nLoss: 0.44413384795188904,epoch:1751485: : 1it [00:00,  3.47it/s]\nLoss: 0.19966763257980347,epoch:1751486: : 1it [00:00,  2.62it/s]\nLoss: 0.35338231921195984,epoch:1751487: : 1it [00:00,  2.09it/s]\nLoss: 0.22077350318431854,epoch:1751488: : 1it [00:00,  1.63it/s]\nLoss: 0.30358806252479553,epoch:1751489: : 1it [00:00,  1.53it/s]\nLoss: 0.22699196636676788,epoch:1751490: : 1it [00:00,  1.66it/s]\nLoss: 0.4470691382884979,epoch:1751491: : 1it [00:00,  3.03it/s]\nLoss: 0.288632869720459,epoch:1751492: : 1it [00:00,  2.51it/s]\nLoss: 0.5180795192718506,epoch:1751493: : 1it [00:00,  2.58it/s]\nLoss: 0.21792273223400116,epoch:1751494: : 1it [00:00,  2.35it/s]\nLoss: 0.5741000771522522,epoch:1751495: : 1it [00:00,  2.50it/s]\nLoss: 0.2916862666606903,epoch:1751496: : 1it [00:00,  2.08it/s]\nLoss: 0.32847267389297485,epoch:1751497: : 1it [00:00,  2.48it/s]\nLoss: 0.4378669857978821,epoch:1751498: : 1it [00:00,  2.36it/s]\nLoss: 0.2133074849843979,epoch:1751499: : 1it [00:00,  2.58it/s]\nLoss: 0.3586232364177704,epoch:1751500: : 1it [00:00,  2.65it/s]\nLoss: 0.16388142108917236,epoch:1751501: : 1it [00:00,  2.28it/s]\nLoss: 0.38046032190322876,epoch:1751502: : 1it [00:00,  2.57it/s]\nLoss: 0.3290764093399048,epoch:1751503: : 1it [00:00,  2.87it/s]\nLoss: 0.33219102025032043,epoch:1751504: : 1it [00:00,  2.18it/s]\nLoss: 0.16604477167129517,epoch:1751505: : 1it [00:00,  2.59it/s]\nLoss: 0.48698002099990845,epoch:1751506: : 1it [00:00,  2.24it/s]\nLoss: 0.3315191864967346,epoch:1751507: : 1it [00:00,  3.24it/s]\nLoss: 0.33150896430015564,epoch:1751508: : 1it [00:00,  2.74it/s]\nLoss: 0.22738821804523468,epoch:1751509: : 1it [00:00,  2.79it/s]\nLoss: 0.4541550576686859,epoch:1751510: : 1it [00:00,  2.03it/s]\nLoss: 0.40692010521888733,epoch:1751511: : 1it [00:00,  3.05it/s]\nLoss: 0.3952178657054901,epoch:1751512: : 1it [00:00,  2.08it/s]\nLoss: 0.4008726179599762,epoch:1751513: : 1it [00:00,  2.75it/s]\nLoss: 0.3534391224384308,epoch:1751514: : 1it [00:00,  2.85it/s]\nLoss: 0.4120819568634033,epoch:1751515: : 1it [00:00,  2.58it/s]\nLoss: 0.23657523095607758,epoch:1751516: : 1it [00:00,  2.62it/s]\nLoss: 0.24771106243133545,epoch:1751517: : 1it [00:00,  2.54it/s]\nLoss: 0.4238284230232239,epoch:1751518: : 1it [00:00,  2.66it/s]\nLoss: 0.3306226134300232,epoch:1751519: : 1it [00:00,  1.79it/s]\nLoss: 0.33285096287727356,epoch:1751520: : 1it [00:00,  2.64it/s]\nLoss: 0.12889884412288666,epoch:1751521: : 1it [00:00,  2.53it/s]\nLoss: 0.40622678399086,epoch:1751522: : 1it [00:00,  2.14it/s]\nLoss: 0.21339689195156097,epoch:1751523: : 1it [00:00,  2.74it/s]\nLoss: 0.5095310807228088,epoch:1751524: : 1it [00:00,  2.11it/s]\nLoss: 0.32770630717277527,epoch:1751525: : 1it [00:00,  2.27it/s]\nLoss: 0.4755278527736664,epoch:1751526: : 1it [00:00,  2.27it/s]\nLoss: 0.3189566135406494,epoch:1751527: : 1it [00:00,  2.44it/s]\nLoss: 0.47521883249282837,epoch:1751528: : 1it [00:00,  1.99it/s]\nLoss: 0.4699195921421051,epoch:1751529: : 1it [00:00,  1.79it/s]\nLoss: 0.33913201093673706,epoch:1751530: : 1it [00:00,  2.75it/s]\nLoss: 0.45462751388549805,epoch:1751531: : 1it [00:00,  2.83it/s]\nLoss: 0.31701454520225525,epoch:1751532: : 1it [00:00,  3.21it/s]\nLoss: 0.27295395731925964,epoch:1751533: : 1it [00:00,  2.53it/s]\nLoss: 0.3185063302516937,epoch:1751534: : 1it [00:00,  2.40it/s]\nLoss: 0.3867165744304657,epoch:1751535: : 1it [00:00,  3.23it/s]\nLoss: 0.3808838427066803,epoch:1751536: : 1it [00:00,  2.69it/s]\nLoss: 0.3686096668243408,epoch:1751537: : 1it [00:00,  2.59it/s]\nLoss: 0.38422390818595886,epoch:1751538: : 1it [00:00,  2.46it/s]\nLoss: 0.32432398200035095,epoch:1751539: : 1it [00:00,  2.62it/s]\nLoss: 0.2769143581390381,epoch:1751540: : 1it [00:00,  2.53it/s]\nLoss: 0.29094526171684265,epoch:1751541: : 1it [00:00,  3.31it/s]\nLoss: 0.28436923027038574,epoch:1751542: : 1it [00:00,  2.61it/s]\nLoss: 0.35890495777130127,epoch:1751543: : 1it [00:00,  2.06it/s]\nLoss: 0.5515503287315369,epoch:1751544: : 1it [00:00,  2.44it/s]\nLoss: 0.24189649522304535,epoch:1751545: : 1it [00:00,  2.43it/s]\nLoss: 0.5348460078239441,epoch:1751546: : 1it [00:00,  1.99it/s]\nLoss: 0.1449500173330307,epoch:1751547: : 1it [00:00,  1.78it/s]\nLoss: 0.3821233808994293,epoch:1751548: : 1it [00:00,  2.28it/s]\nLoss: 0.1951947659254074,epoch:1751549: : 1it [00:00,  2.66it/s]\nLoss: 0.18927519023418427,epoch:1751550: : 1it [00:00,  2.68it/s]\nLoss: 0.3879167139530182,epoch:1751551: : 1it [00:00,  3.00it/s]\nLoss: 0.3376797139644623,epoch:1751552: : 1it [00:00,  2.66it/s]\nLoss: 0.3570210039615631,epoch:1751553: : 1it [00:00,  2.41it/s]\nLoss: 0.3457328677177429,epoch:1751554: : 1it [00:00,  2.58it/s]\nLoss: 0.701729953289032,epoch:1751555: : 1it [00:00,  2.93it/s]\nLoss: 0.2207777053117752,epoch:1751556: : 1it [00:00,  2.68it/s]\nLoss: 0.26123443245887756,epoch:1751557: : 1it [00:00,  2.60it/s]\nLoss: 0.1247764602303505,epoch:1751558: : 1it [00:00,  3.24it/s]\nLoss: 0.3837907910346985,epoch:1751559: : 1it [00:00,  2.52it/s]\nLoss: 0.15198004245758057,epoch:1751560: : 1it [00:00,  2.64it/s]\nLoss: 0.6179494857788086,epoch:1751561: : 1it [00:00,  2.34it/s]\nLoss: 0.21976371109485626,epoch:1751562: : 1it [00:00,  2.27it/s]\nLoss: 0.34891581535339355,epoch:1751563: : 1it [00:00,  2.48it/s]\nLoss: 0.28940701484680176,epoch:1751564: : 1it [00:00,  2.02it/s]\nLoss: 0.37365055084228516,epoch:1751565: : 1it [00:00,  1.97it/s]\nLoss: 0.3176242411136627,epoch:1751566: : 1it [00:00,  1.95it/s]\nLoss: 0.36795949935913086,epoch:1751567: : 1it [00:00,  1.90it/s]\nLoss: 0.5282480716705322,epoch:1751568: : 1it [00:00,  2.27it/s]\n0it [00:00, ?it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[7], line 292\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m checkpoint_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    290\u001b[0m     load_checkpoint(checkpoint_path, model, optimizer, reset_optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 292\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcheckpoint_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckpoint_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcheckpoint_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msyncnet_checkpoint_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnepochs\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[7], line 164\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(device, model, train_data_loader, test_data_loader, optimizer, checkpoint_dir, checkpoint_interval, nepochs)\u001b[0m\n\u001b[1;32m    162\u001b[0m         prog_bar \u001b[38;5;241m=\u001b[39m tqdm(\u001b[38;5;28menumerate\u001b[39m(train_data_loader))\n\u001b[1;32m    163\u001b[0m \u001b[38;5;66;03m#         print(global_epoch,'global_epoch')\u001b[39;00m\n\u001b[0;32m--> 164\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m step, (x, mel, y) \u001b[38;5;129;01min\u001b[39;00m prog_bar:\n\u001b[1;32m    165\u001b[0m \u001b[38;5;66;03m#             print(step,'step')\u001b[39;00m\n\u001b[1;32m    166\u001b[0m             model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m    167\u001b[0m             optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tqdm/std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1181\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1182\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1185\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    677\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 678\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    680\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n","Cell \u001b[0;32mIn[7], line 107\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    105\u001b[0m all_read \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fname \u001b[38;5;129;01min\u001b[39;00m window_fnames:\n\u001b[0;32m--> 107\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m img \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    109\u001b[0m         all_read \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"# 学习训练代码.\nimport glob\n# print(glob.glob('./lrs2_preprocessed/LRS2_partly/*/*.jpg'))\n# print(glob.glob('./*.*'))\n\nfrom os.path import dirname, join, basename, isfile\nfrom tqdm import tqdm\n\nfrom models import SyncNet_color as SyncNet\nfrom models import Wav2Lip as Wav2Lip\nimport audio\n\nimport torch\nfrom torch import nn\nfrom torch import optim\nimport torch.backends.cudnn as cudnn\nfrom torch.utils import data as data_utils\nimport numpy as np\n\nfrom glob import glob\n\nimport os, random, cv2, argparse\nfrom hparams import hparams, get_image_list\n\nparser = argparse.ArgumentParser(description='Code to train the Wav2Lip model without the visual quality discriminator')\n\nparser.add_argument(\"--data_root\", help=\"Root folder of the preprocessed LRS2 dataset\", required=False, type=str)\n\nparser.add_argument('--checkpoint_dir', help='Save checkpoints to this directory', required=False, type=str)\nparser.add_argument('--syncnet_checkpoint_path', help='Load the pre-trained Expert discriminator', required=False, type=str)\n\nparser.add_argument('--checkpoint_path', help='Resume from this checkpoint', default=None, type=str)\nppp='/kaggle/working/Wav2Lip/'\nargs = parser.parse_args('')\n# args.data_root='lrs2_preprocessed'\nargs.checkpoint_dir='newmodel'\nargs.syncnet_checkpoint_path=ppp+'checkpoints/lipsync_expert.pth'\nargs.checkpoint_path=ppp+'checkpoints/wav2lip_gan.pth'\n\nhparams.checkpoint_interval=300\n\nhparams.num_workers=0\nhparams.syncnet_batch_size=1000\nhparams.syncnet_lr=3e-5\n\n\n\n\n\n\n\n\n\nglobal_step = 0\nglobal_epoch = 0\nuse_cuda = torch.cuda.is_available()\nprint('use_cuda: {}'.format(use_cuda))\n\nsyncnet_T = 5               # 视频片段长度\nsyncnet_mel_step_size = 16  # 音频片段长度\n\nclass Dataset(object):\n    def __init__(self, split):\n        # self.all_videos = get_image_list(args.data_root, split)\n        self.all_videos =glob('my_data_preprocessed/20171116/*')\n        print(self.all_videos)\n    def get_frame_id(self, frame):\n        return int(basename(frame).split('.')[0])\n\n    def get_window(self, start_frame):\n        start_id = self.get_frame_id(start_frame)\n        vidname = dirname(start_frame)\n\n        window_fnames = []\n        for frame_id in range(start_id, start_id + syncnet_T):\n            frame = join(vidname, '{}.jpg'.format(frame_id)) # 取5帧\n            if not isfile(frame):\n                return None\n            window_fnames.append(frame)\n        return window_fnames\n\n    def read_window(self, window_fnames):\n        if window_fnames is None: return None\n        window = []\n        for fname in window_fnames:\n            img = cv2.imread(fname)\n            if img is None:\n                return None\n            try:\n                img = cv2.resize(img, (hparams.img_size, hparams.img_size))\n            except Exception as e:\n                return None\n\n            window.append(img)\n\n        return window\n\n    def crop_audio_window(self, spec, start_frame):\n        if type(start_frame) == int:\n            start_frame_num = start_frame\n        else:\n            start_frame_num = self.get_frame_id(start_frame) # 0-indexing ---> 1-indexing\n        start_idx = int(80. * (start_frame_num / float(hparams.fps)))\n        # mel普一秒是80个数, (start_frame_num / float(hparams.fps) 当前流逝时间.\n        end_idx = start_idx + syncnet_mel_step_size\n\n        return spec[start_idx : end_idx, :]\n\n    def get_segmented_mels(self, spec, start_frame):\n        mels = []\n        assert syncnet_T == 5\n        start_frame_num = self.get_frame_id(start_frame) + 1 # 0-indexing ---> 1-indexing\n        if start_frame_num - 2 < 0: return None\n        for i in range(start_frame_num, start_frame_num + syncnet_T):\n            m = self.crop_audio_window(spec, i - 2)\n            if m.shape[0] != syncnet_mel_step_size:\n                return None\n            mels.append(m.T)\n\n        mels = np.asarray(mels)\n\n        return mels\n\n    def prepare_window(self, window):\n        # 3 x T x H x W\n        x = np.asarray(window) / 255.\n        x = np.transpose(x, (3, 0, 1, 2))\n\n        return x\n\n    def __len__(self):\n        return len(self.all_videos)\n\n    def __getitem__(self, idx):\n        while 1:\n            idx = random.randint(0, len(self.all_videos) - 1)\n            vidname = self.all_videos[idx]\n            img_names = list(glob(join(vidname, '*.jpg'))) # 获取视频的所有贞.\n            if len(img_names) <= 3 * syncnet_T:\n                continue\n            \n            img_name = random.choice(img_names)\n            wrong_img_name = random.choice(img_names)\n            while wrong_img_name == img_name:\n                wrong_img_name = random.choice(img_names)\n#------根据抽样得到窗口贞.\n            window_fnames = self.get_window(img_name)\n            wrong_window_fnames = self.get_window(wrong_img_name)\n            if window_fnames is None or wrong_window_fnames is None:\n                continue\n\n            window = self.read_window(window_fnames)\n            if window is None:\n                continue\n\n            wrong_window = self.read_window(wrong_window_fnames)\n            if wrong_window is None:\n                continue\n\n            try:\n                aaa=list(glob(join(vidname, '*.wav')))[0]\n                wavpath = join(vidname, \"audio.wav\")\n                wav = audio.load_wav(aaa, hparams.sample_rate)\n\n                orig_mel = audio.melspectrogram(wav).T\n            except Exception as e:\n                continue\n            # mel 当前时间点, 0.2秒钟的音频特征.\n            mel = self.crop_audio_window(orig_mel.copy(), img_name)\n            \n            if (mel.shape[0] != syncnet_mel_step_size):\n                continue\n            # indiv_mels是上一个mel的后续5个.\n            indiv_mels = self.get_segmented_mels(orig_mel.copy(), img_name)\n            if indiv_mels is None: continue\n\n            window = self.prepare_window(window)\n            y = window.copy() #======作为标签.\n            window[:, :, window.shape[2]//2:] = 0. # 遮挡住视频的下半部分人脸.\n#   window: 34帧到39帧, mel:34的音频. inv_mel: 35到39的音频. wrong_window: 58到62的帧.\n            wrong_window = self.prepare_window(wrong_window)\n            x = np.concatenate([window, wrong_window], axis=0)\n\n            x = torch.FloatTensor(x)\n            mel = torch.FloatTensor(mel.T).unsqueeze(0)\n            indiv_mels = torch.FloatTensor(indiv_mels).unsqueeze(1)\n            y = torch.FloatTensor(y)\n            return x, indiv_mels, mel, y\n\ndef save_sample_images(x, g, gt, global_step, checkpoint_dir):\n    x = (x.detach().cpu().numpy().transpose(0, 2, 3, 4, 1) * 255.).astype(np.uint8)\n    g = (g.detach().cpu().numpy().transpose(0, 2, 3, 4, 1) * 255.).astype(np.uint8)\n    gt = (gt.detach().cpu().numpy().transpose(0, 2, 3, 4, 1) * 255.).astype(np.uint8)\n\n    refs, inps = x[..., 3:], x[..., :3]\n    folder = join(checkpoint_dir, \"samples_step{:09d}\".format(global_step))\n    if not os.path.exists(folder): os.mkdir(folder)\n    collage = np.concatenate((refs, inps, g, gt), axis=-2)\n    for batch_idx, c in enumerate(collage):\n        for t in range(len(c)):\n            cv2.imwrite('{}/{}_{}.jpg'.format(folder, batch_idx, t), c[t])\n\nlogloss = nn.BCELoss()\ndef cosine_loss(a, v, y):\n    d = nn.functional.cosine_similarity(a, v)\n    loss = logloss(d.unsqueeze(1), y)\n\n    return loss\n\ndevice = torch.device(\"cuda\" if use_cuda else \"cpu\")\nsyncnet = SyncNet().to(device)\nfor p in syncnet.parameters():\n    p.requires_grad = False\n\nrecon_loss = nn.L1Loss()\ndef get_sync_loss(mel, g):\n    g = g[:, :, :, g.size(3)//2:]\n    g = torch.cat([g[:, :, i] for i in range(syncnet_T)], dim=1)\n    # B, 3 * T, H//2, W\n    a, v = syncnet(mel, g)\n    y = torch.ones(g.size(0), 1).float().to(device)\n    return cosine_loss(a, v, y)\n\ndef train(device, model, train_data_loader, test_data_loader, optimizer,\n          checkpoint_dir=None, checkpoint_interval=None, nepochs=None):\n\n    global global_step, global_epoch\n    resumed_step = global_step\n \n    while global_epoch < nepochs:\n        print('Starting Epoch: {}'.format(global_epoch))\n        running_sync_loss, running_l1_loss = 0., 0.5\n        prog_bar = tqdm(enumerate(train_data_loader))\n        for step, (x, indiv_mels, mel, gt) in prog_bar:\n            model.train()\n            optimizer.zero_grad()\n\n            # Move data to CUDA device\n            x = x.to(device)\n            mel = mel.to(device)\n            indiv_mels = indiv_mels.to(device)\n            gt = gt.to(device)\n# 输入音频和x. 输出g\n            g = model(indiv_mels, x) # 输入后续mel和当前图片, 计算后续的图片.\n\n            if hparams.syncnet_wt > 0.:\n                sync_loss = get_sync_loss(mel, g) # 这个是同步分数, 用来判定音频和视频是否同步.\n            else:\n                sync_loss = 0.\n\n            l1loss = recon_loss(g, gt) # 重构loss.\n\n            loss = hparams.syncnet_wt * sync_loss + (1 - hparams.syncnet_wt) * l1loss\n            loss.backward()\n            optimizer.step()\n            if 0:#========禁掉eval\n             if global_step % checkpoint_interval == 0:\n                save_sample_images(x, g, gt, global_step, checkpoint_dir)\n\n            global_step += 1\n            cur_session_steps = global_step - resumed_step\n\n            running_l1_loss += l1loss.item()\n            if hparams.syncnet_wt > 0.:\n                running_sync_loss += sync_loss.item()\n            else:\n                running_sync_loss += 0.\n\n            if global_step == 1 or global_step % checkpoint_interval == 0:\n                save_checkpoint(\n                    model, optimizer, global_step, checkpoint_dir, global_epoch)\n            if 0:#==========禁掉eval\n                if global_step == 1 or global_step % hparams.eval_interval == 0:\n                    with torch.no_grad():\n                        average_sync_loss = eval_model(test_data_loader, global_step, device, model, checkpoint_dir)\n\n                        if average_sync_loss < .75:\n                            hparams.set_hparam('syncnet_wt', 0.01) # without image GAN a lesser weight is sufficient\n            # print(f'loss:{loss},global_step:{global_step}')\n            # prog_bar.set_description('L1: {}, Sync Loss: {}'.format(running_l1_loss / (step + 1),\n            #                                                         running_sync_loss / (step + 1)))\n            prog_bar.set_description(f'loss:{loss},global_step:{global_step}')\n\n        global_epoch += 1\n        \n\ndef eval_model(test_data_loader, global_step, device, model, checkpoint_dir):\n    eval_steps = 700\n    print('Evaluating for {} steps'.format(eval_steps))\n    sync_losses, recon_losses = [], []\n    step = 0\n    while 1:\n        for x, indiv_mels, mel, gt in test_data_loader:\n            step += 1\n            model.eval()\n\n            # Move data to CUDA device\n            x = x.to(device)\n            gt = gt.to(device)\n            indiv_mels = indiv_mels.to(device)\n            mel = mel.to(device)\n\n            g = model(indiv_mels, x)\n\n            sync_loss = get_sync_loss(mel, g)\n            l1loss = recon_loss(g, gt)\n\n            sync_losses.append(sync_loss.item())\n            recon_losses.append(l1loss.item())\n\n            if step > eval_steps: \n                averaged_sync_loss = sum(sync_losses) / len(sync_losses)\n                averaged_recon_loss = sum(recon_losses) / len(recon_losses)\n\n                print('L1: {}, Sync loss: {}'.format(averaged_recon_loss, averaged_sync_loss))\n\n                return averaged_sync_loss\n\ndef save_checkpoint(model, optimizer, step, checkpoint_dir, epoch):\n\n    checkpoint_path = join(\n        checkpoint_dir, \"checkpoint_step{:09d}.pth\".format(global_step))\n    optimizer_state = optimizer.state_dict() if hparams.save_optimizer_state else None\n    torch.save({\n        \"state_dict\": model.state_dict(),\n        \"optimizer\": optimizer_state,\n        \"global_step\": step,\n        \"global_epoch\": epoch,\n    }, checkpoint_path)\n    print(\"Saved checkpoint:\", checkpoint_path)\n\n\ndef _load(checkpoint_path):\n    if use_cuda:\n        checkpoint = torch.load(checkpoint_path)\n    else:\n        checkpoint = torch.load(checkpoint_path,\n                                map_location=lambda storage, loc: storage)\n    return checkpoint\n\ndef load_checkpoint(path, model, optimizer, reset_optimizer=False, overwrite_global_states=True):\n    global global_step\n    global global_epoch\n\n    print(\"Load checkpoint from: {}\".format(path))\n    checkpoint = _load(path)\n    s = checkpoint[\"state_dict\"]\n    new_s = {}\n    for k, v in s.items():\n        new_s[k.replace('module.', '')] = v\n    model.load_state_dict(new_s)\n    if not reset_optimizer:\n        optimizer_state = checkpoint[\"optimizer\"]\n        if optimizer_state is not None:\n            print(\"Load optimizer state from {}\".format(path))\n            optimizer.load_state_dict(checkpoint[\"optimizer\"])\n    if overwrite_global_states:\n        global_step = checkpoint[\"global_step\"]\n        global_epoch = checkpoint[\"global_epoch\"]\n\n    return model\n\nif __name__ == \"__main__\":\n    checkpoint_dir = args.checkpoint_dir\n\n    # Dataset and Dataloader setup\n    train_dataset = Dataset('train')\n    test_dataset = Dataset('val')\n    hparams.batch_size=1\n    hparams.num_workers=0\n    train_data_loader = data_utils.DataLoader(\n        train_dataset, batch_size=hparams.batch_size, shuffle=True,\n        num_workers=hparams.num_workers)\n\n    test_data_loader = data_utils.DataLoader(\n        test_dataset, batch_size=hparams.batch_size,\n        num_workers=hparams.num_workers)\n\n    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n\n    # Model\n    model = Wav2Lip().to(device)\n    print('total trainable params {}'.format(sum(p.numel() for p in model.parameters() if p.requires_grad)))\n\n    optimizer = optim.Adam([p for p in model.parameters() if p.requires_grad],\n                           lr=hparams.initial_learning_rate)\n\n    if args.checkpoint_path is not None: # 加载wav2lip 的权重\n        load_checkpoint(args.checkpoint_path, model, optimizer, reset_optimizer=False)\n        \n    load_checkpoint(args.syncnet_checkpoint_path, syncnet, None, reset_optimizer=True, overwrite_global_states=False)  # 加载sync打分模型.\n#===========加载完syncnet和model\n    if not os.path.exists(checkpoint_dir):\n        os.mkdir(checkpoint_dir)\n\n    # Train!\n    train(device, model, train_data_loader, test_data_loader, optimizer,\n              checkpoint_dir=checkpoint_dir,\n              checkpoint_interval=hparams.checkpoint_interval,\n              nepochs=hparams.nepochs)","metadata":{"execution":{"iopub.status.busy":"2023-12-01T06:53:28.802994Z","iopub.execute_input":"2023-12-01T06:53:28.803402Z","iopub.status.idle":"2023-12-01T06:53:49.872508Z","shell.execute_reply.started":"2023-12-01T06:53:28.803373Z","shell.execute_reply":"2023-12-01T06:53:49.871069Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"use_cuda: True\n['my_data_preprocessed/20171116/section_2_028', 'my_data_preprocessed/20171116/section_3_000', 'my_data_preprocessed/20171116/section_1_081', 'my_data_preprocessed/20171116/section_2_033', 'my_data_preprocessed/20171116/section_1_049', 'my_data_preprocessed/20171116/section_2_024', 'my_data_preprocessed/20171116/section_2_020', 'my_data_preprocessed/20171116/section_1_024', 'my_data_preprocessed/20171116/section_1_068', 'my_data_preprocessed/20171116/section_2_016']\n['my_data_preprocessed/20171116/section_2_028', 'my_data_preprocessed/20171116/section_3_000', 'my_data_preprocessed/20171116/section_1_081', 'my_data_preprocessed/20171116/section_2_033', 'my_data_preprocessed/20171116/section_1_049', 'my_data_preprocessed/20171116/section_2_024', 'my_data_preprocessed/20171116/section_2_020', 'my_data_preprocessed/20171116/section_1_024', 'my_data_preprocessed/20171116/section_1_068', 'my_data_preprocessed/20171116/section_2_016']\ntotal trainable params 36298035\nLoad checkpoint from: /kaggle/working/Wav2Lip/checkpoints/wav2lip_gan.pth\nLoad optimizer state from /kaggle/working/Wav2Lip/checkpoints/wav2lip_gan.pth\nLoad checkpoint from: /kaggle/working/Wav2Lip/checkpoints/lipsync_expert.pth\nStarting Epoch: 88\n","output_type":"stream"},{"name":"stderr","text":"loss:0.09145378321409225,global_step:258010: : 10it [00:01,  7.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"Starting Epoch: 89\n","output_type":"stream"},{"name":"stderr","text":"loss:0.08842376619577408,global_step:258020: : 10it [00:01,  7.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"Starting Epoch: 90\n","output_type":"stream"},{"name":"stderr","text":"loss:0.08006428927183151,global_step:258030: : 10it [00:01,  9.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"Starting Epoch: 91\n","output_type":"stream"},{"name":"stderr","text":"loss:0.07307977974414825,global_step:258040: : 10it [00:01,  9.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"Starting Epoch: 92\n","output_type":"stream"},{"name":"stderr","text":"loss:0.07955589145421982,global_step:258050: : 10it [00:01,  9.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"Starting Epoch: 93\n","output_type":"stream"},{"name":"stderr","text":"loss:0.07865969836711884,global_step:258060: : 10it [00:01,  8.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"Starting Epoch: 94\n","output_type":"stream"},{"name":"stderr","text":"loss:0.06583227962255478,global_step:258070: : 10it [00:01,  7.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"Starting Epoch: 95\n","output_type":"stream"},{"name":"stderr","text":"loss:0.05770936235785484,global_step:258080: : 10it [00:01,  9.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"Starting Epoch: 96\n","output_type":"stream"},{"name":"stderr","text":"loss:0.05263358727097511,global_step:258090: : 10it [00:01,  9.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"Starting Epoch: 97\n","output_type":"stream"},{"name":"stderr","text":"loss:0.05557217448949814,global_step:258100: : 10it [00:01,  7.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"Starting Epoch: 98\n","output_type":"stream"},{"name":"stderr","text":"loss:0.051906291395425797,global_step:258110: : 10it [00:01,  7.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"Starting Epoch: 99\n","output_type":"stream"},{"name":"stderr","text":"loss:0.04179990664124489,global_step:258120: : 10it [00:01,  8.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"Starting Epoch: 100\n","output_type":"stream"},{"name":"stderr","text":"loss:0.045833129435777664,global_step:258130: : 10it [00:01,  8.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"Starting Epoch: 101\n","output_type":"stream"},{"name":"stderr","text":"loss:0.04241945967078209,global_step:258140: : 10it [00:01,  8.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"Starting Epoch: 102\n","output_type":"stream"},{"name":"stderr","text":"loss:0.04783051460981369,global_step:258150: : 10it [00:01,  8.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"Starting Epoch: 103\n","output_type":"stream"},{"name":"stderr","text":"loss:0.04739758372306824,global_step:258158: : 8it [00:01,  7.90it/s] \n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[10], line 397\u001b[0m\n\u001b[1;32m    394\u001b[0m     os\u001b[38;5;241m.\u001b[39mmkdir(checkpoint_dir)\n\u001b[1;32m    396\u001b[0m \u001b[38;5;66;03m# Train!\u001b[39;00m\n\u001b[0;32m--> 397\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m          \u001b[49m\u001b[43mcheckpoint_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckpoint_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m          \u001b[49m\u001b[43mcheckpoint_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckpoint_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m          \u001b[49m\u001b[43mnepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnepochs\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[10], line 244\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(device, model, train_data_loader, test_data_loader, optimizer, checkpoint_dir, checkpoint_interval, nepochs)\u001b[0m\n\u001b[1;32m    242\u001b[0m             gt \u001b[38;5;241m=\u001b[39m gt\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    243\u001b[0m \u001b[38;5;66;03m# 输入音频和x. 输出g\u001b[39;00m\n\u001b[0;32m--> 244\u001b[0m             g \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindiv_mels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# 输入后续mel和当前图片, 计算后续的图片.\u001b[39;00m\n\u001b[1;32m    246\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m hparams\u001b[38;5;241m.\u001b[39msyncnet_wt \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.\u001b[39m:\n\u001b[1;32m    247\u001b[0m                 sync_loss \u001b[38;5;241m=\u001b[39m get_sync_loss(mel, g) \u001b[38;5;66;03m# 这个是同步分数, 用来判定音频和视频是否同步.\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/kaggle/working/xuni8/models/wav2lip.py:106\u001b[0m, in \u001b[0;36mWav2Lip.forward\u001b[0;34m(self, audio_sequences, face_sequences)\u001b[0m\n\u001b[1;32m    104\u001b[0m x \u001b[38;5;241m=\u001b[39m audio_embedding\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mface_decoder_blocks:\n\u001b[0;32m--> 106\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#每一次,音频编码, concat 视频编码.\u001b[39;00m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    108\u001b[0m         x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((x, feats[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/kaggle/working/xuni8/models/conv.py:43\u001b[0m, in \u001b[0;36mConv2dTranspose.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 43\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(out)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:171\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    164\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2450\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2447\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[1;32m   2448\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m-> 2450\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2451\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\n\u001b[1;32m   2452\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]}]}